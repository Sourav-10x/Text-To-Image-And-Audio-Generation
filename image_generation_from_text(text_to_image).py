# -*- coding: utf-8 -*-
"""Image Generation from Text(Text-to-Image).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xYVu7uxabUqOhps7-7MTNTfAKU-srZCd
"""

!nvidia-smi

!pip install transformers diffusers accelerate

from diffusers import StableDiffusionPipeline
import matplotlib.pyplot as plt
import torch

!pip show torch

model_id="dreamlike-art/dreamlike-diffusion-1.0"

pipe=StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch.float16,use_safetensors=True)

pipe=pipe.to("cuda")

prompt="dreamlikeart, a grungy woman with rainbow hair, travelling between dimensions, dynamic pose, happy, soft eyes and narrow chin, extreme bokeh, dainty figure, long hair straight down, torn kawaii shirt and baggy jeans, In style of by Jordan Grimmer and greg rutkowski, crisp lines and color, complex background, particles, lines, wind, concept art, sharp focus, vivid colors"

image=pipe(prompt).images[0]

image

"""## Parameters

### Num inference steps
### Width,height
### Num images per prompt
"""

def generate_image(pipe, prompt, params):
  img = pipe(prompt, **params).images

  num_images = len(img)

  if(num_images>1):
    fig, ax = plt.subplots(nrows = 1, ncols= num_images)

    for i in range(num_images):
      ax[i].imshow(img[i])
      ax[i].axis("off")

  else:
    fig = plt.figure()
    plt.imshow(img[0])
    plt.axis('off')

  plt.tight_layout()

prompt="A blue future-like dream bike with multiple features, soft colors, 3d, highly polished"

params={}

generate_image(pipe,prompt,params)

#num_inference_steps

params = {'num_inference_steps': 100}
generate_image(pipe,prompt,params)

params = {'num_inference_steps': 200}
generate_image(pipe,prompt,params)

#height - width

params = {'num_inference_step': 300, 'width':512, 'height': 512}

generate_image(pipe,prompt,params)

#num_images_per_prompt

params = {'num_inference_step': 400, 'width': 512, 'height': 512, 'num_images_per_prompt':3}

generate_image(pipe,prompt,params)

"""# Text to Audio Generation

"""

from transformers import pipeline

text= "Summer School is organised every year."

pipe=pipeline("text-to-speech", model="suno/bark-small")
output=pipe(text)

output

from IPython.display import Audio

Audio(output["audio"],rate=output["sampling_rate"])

